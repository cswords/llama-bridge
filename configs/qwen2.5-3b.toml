# Llama-Bridge Configuration for Qwen2.5-3B
# 
# Small model for testing or low-resource environments.

# ============================================================
# Model Definition
# ============================================================
[models.qwen3b]
n_ubatch = 512
n_batch = 512
cache_type_v = 'f16'
cache_type_k = 'f16'
flash_attn = true
n_threads = 4
path = "Qwen/Qwen2.5-3B-Instruct-GGUF/qwen2.5-3b-instruct-q4_k_m.gguf"

# ============================================================
# Cache Definitions
# ============================================================

[caches.main]
model = "qwen3b"
n_ctx = 131072                     # 128K Theoretical Limit for Qwen2.5
description = "Main conversation"

[caches.fast]
model = "qwen3b"
n_ctx = 32768                       # 32K for fast background tasks
description = "Background tasks"

# ============================================================
# Routing Rules
# ============================================================

[[routes]]
endpoint = "/v1/messages/count_tokens"
cache = "fast"

[[routes]]
match = "*haiku*"
cache = "fast"

[[routes]]
match = "*small*"
cache = "fast"

[[routes]]
match = "*"
cache = "main"
