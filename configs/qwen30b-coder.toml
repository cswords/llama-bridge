# Llama-Bridge Configuration for Qwen3-Coder-30B
# 
# Optimized for mixed use: Claude Code (Main+Fast caches) and Generic Clients.

# ============================================================
# Model Definition
# ============================================================
[models.qwen30b]
path = "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF/Qwen3-Coder-30B-A3B-Instruct-Q5_K_M.gguf"

# ============================================================
# Cache Definitions
# ============================================================

[caches.main]
model = "qwen30b"
n_ctx = 32768                     # 32K Context for main tasks
description = "Main conversation"

[caches.fast]
model = "qwen30b"
n_ctx = 8192                       # 8K Context for background/fast tasks
description = "Background tasks"

# ============================================================
# Routing Rules
# ============================================================

# Token counting
[[routes]]
endpoint = "/v1/messages/count_tokens"
cache = "fast"

# Claude Code's "fast" models -> fast cache
[[routes]]
match = "*haiku*"
cache = "fast"

[[routes]]
match = "*small*"
cache = "fast"

# Default route -> main cache
[[routes]]
match = "*"
cache = "main"
